# Kafka Learn

Этот проект демонстрирует базовое приложение для работы с Apache Kafka. Приложение состоит из одного продюсера и двух типов консьюмеров, которые обрабатывают сообщения из топика Kafka. 
Проект написан на языке Go и использует Docker для развертывания.

## Принципы работы приложения

Приложение реализует модель publish-subscribe с использованием Apache Kafka. Основные компоненты:
- **Продюсер** отправляет сообщения в топик Kafka с использованием асинхронного метода. Сообщения представляют собой сериализованные структуры `Message` в формате JSON.
- **Консьюмеры** считывают сообщения из топика и обрабатывают их. Два типа консьюмеров работают параллельно, каждый со своей группой потребителей (consumer group):
  - **SingleMessageConsumer**: считывает по одному сообщению за раз, автоматически коммитит оффсеты после обработки.
  - **BatchMessageConsumer**: считывает пачку сообщений (минимум 10 за один poll), обрабатывает их в цикле и коммитит оффсеты вручную после обработки всей пачки.
- **Сериализация/десериализация**: Сообщения сериализуются в JSON перед отправкой и десериализуются при получении. Ошибки сериализации/десериализации логируются.
- **Гарантии доставки**: Продюсер настроен на гарантию "At Least Once" (acks=all, retries=3), обеспечивая доставку сообщений даже при временных сбоях.

Каждый тип консьюмера запускается в двух экземплярах, что позволяет демонстрировать параллельную обработку сообщений с учетом взаимодействия идентификатора групп консьюмеров.

## Описание классов

### 1. `Message` (pkg/message/message.go)
- **Описание**: Структура, представляющая сообщение, отправляемое в Kafka.
- **Поля**:
  - `Message` (string): Содержимое сообщения.
- **Назначение**: Используется для сериализации в JSON перед отправкой продюсером и десериализации в консьюмерах.
- **Принципы работы**: Простая структура для передачи данных. При сериализации/десериализации ошибки обрабатываются с выводом в консоль.

### 2. `MessageProducer` (kafka-writer/messager/message-producer.go)
- **Описание**: Компонент, отправляющий сообщения в топик Kafka.
- **Принципы работы**:
  - Создает экземпляр продюсера с использованием библиотеки `confluent-kafka-go`.
  - Настраивается с параметрами:
    - `acks=all`: Гарантия "At Least Once", брокер подтверждает запись сообщения.
    - `retries=3`: Повторные попытки отправки при временных сбоях.
  - Асинхронно отправляет сообщения (`Message`) в топик `topic`.
  - Сериализует сообщения в JSON и выводит их в консоль перед отправкой.
  - Обрабатывает ошибки сериализации и отправки, логируя их.
- **Назначение**: Генерирует и публикует сообщения в топик для последующей обработки консьюмерами.

### 3. `MessageConsumer` (kafka-reader/consumer/consumer.go)
- **Описание**: Консьюмер, обрабатывающий сообщения.
- **Принципы работы**:
  - Работает в группе потребителей `group-id` (задается флагом).
  - Считывает сообщения из топика `topic`.
  - В зависимости от настройки `mode` (задается флагом) обрабатывает по одному сообщению (kafka-reader/consumer/single-consume.go) или множеству (kafka-reader/consumer/batch-consume.go).
- **Назначение**: Демонстрирует обработку сообщений по одному с автоматическим управлением оффсетами.

## Требования

- Docker и Docker Compose
- Go 1.24+
- Установленная библиотека `confluent-kafka-go` (`go get github.com/confluentinc/confluent-kafka-go/kafka`)

## Инструкции по запуску

1. **Клонируйте репозиторий**:
   ```bash
   git clone https://github.com/posolwar/kafka-learn.git
   cd kafka-learn
   ```

2. **Создайте топик**:
   Запустите Kafka через Docker Compose и создайте топик `topic` с 3 партициями и 2 репликами:
   ```bash
   docker compose -f docker-compose.yml up -d
   docker exec -it kafka kafka-topics --create --bootstrap-server localhost:9092 --topic topic --partitions 3 --replication-factor 2
   ```

3. **Создаем образ для продюсера и консьюмеров**:
   ```bash
   docker compose -f docker-compose-create-image.yaml up -d
   ```

4. **Запускаем продюсеры и консьюмеры**:
   ```bash
   docker compose -f docker-compose-up-kafka-reader-writer.yaml up -d
   ```

## Проверка работоспособности

Чтобы убедиться, что приложение работает в соответствии с заданием, выполните следующие шаги:

1. **Проверка топика**:
   Убедитесь, что топик `topic` создан с 3 партициями и 2 репликами:
   ```bash
   docker compose exec kafka-0 kafka-topics.sh --describe --topic topic --bootstrap-server localhost:9092
   ```
   Ожидаемый вывод:
   ```
   Topic: topic	TopicId: bcCTyJXPSZKwPt0vfT9Wbg	PartitionCount: 3	ReplicationFactor: 2	Configs: 
      Topic: topic	Partition: 0	Leader: 2	Replicas: 2,0	Isr: 2,0
      Topic: topic	Partition: 1	Leader: 0	Replicas: 0,1	Isr: 0,1
      Topic: topic	Partition: 2	Leader: 1	Replicas: 1,2	Isr: 1,2
   ```

2. **Проверка продюсера**:
   В логах продюсера (`docker-compose logs producer`) должны отображаться сообщения вида:
   ```
   producer-1           | 2025/05/11 19:32:16 INFO Сообщение доставлено message="{Message:test message}" topic=topic partition=0 offset=0
   ```
   Это подтверждает, что сообщения сериализуются в JSON и отправляются в топик.

3. **Отправка новых сообщений**:
   Пример команды для отправки новыйх сообщений в топик
   ```
   go run kafka-writer/main.go -topic=topic -bootstrap-servers=localhost:9094 -message="text" -schema-registry="http://127.0.0.1:8081"
   ```

4. **Проверка SingleMessageConsumer**:
   В логах (`docker-compose logs single-message-consumer`) каждого экземпляра (2 реплики) должны отображаться обработанные сообщения:
   ```
   kafka-learn_kafka-networksingle-consumer-1-1  | 2025/05/11 19:32:58 INFO SingleMessageConsumer получено сообщение:=text
   ```
   Сообщения обрабатываются по одному, и оффсеты коммитятся автоматически.

5. **Проверка BatchMessageConsumer**:
   В логах (`docker-compose logs batch-message-consumer`) каждого экземпляра (2 реплики) должны отображаться пачки сообщений:
   ```
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Полученный список сообщений "Кол-во сообщений"=10
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=0 подробности="test message"
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=1 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=2 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=3 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=4 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=5 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=6 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=7 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=8 подробности=text
   batch-consumer-2-1   | 2025/05/11 19:33:24 INFO Сообщение номер=9 подробности=text
   ```
   Сообщения обрабатываются пачками (по 10), и оффсеты коммитятся вручную после обработки.

6. **Проверка параллельной обработки**:
   Убедитесь, что оба типа консьюмеров (с разными `group_id`) получают одни и те же сообщения. Это можно проверить, сравнивая ID сообщений в логах `single-consumer-1` и `batch-consumer-1`.

