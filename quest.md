# Настройка кластера и реализация продюсера с двумя консьюмерами

## Тема проекта
Настройка кластера и реализация продюсера с двумя консьюмерами.

## Цель выполнения проекта
Применить на практике знания об основах Apache Kafka, укрепить понимание её архитектуры, ключевых компонентов и возможностей.

## Как выполнить проект
Проект выполняется на одном из трёх языков: **Java**, **Python** или **Go**. Выполняйте проект локально на своём компьютере, использование облачных сервисов необязательно. Материалы можно хранить в репозитории на GitHub.

В проверочной работе 1 вы развернули локальный Kafka-кластер из трёх серверов. Используйте его для выполнения проекта.

###  Шаг 1. Создание топика
Создайте топик с **3 партициями** и **2 репликами** через консоль.
 
###  Шаг 2. Создание приложения
Создайте приложение, состоящее из:
- **1 продюсера**, отправляющего сообщения в Kafka-топик (модель push).
- **2 консьюмеров**:
  - **SingleMessageConsumer**: считывает по одному сообщению, обрабатывает его и автоматически коммитит оффсет.
  - **BatchMessageConsumer**: считывает минимум 10 сообщений за один `poll`, обрабатывает их в цикле и коммитит оффсет один раз после обработки пачки.

**Подсказки**:
- Продюсер использует асинхронный метод отправки, но продюсер и консьюмеры работают с потоками данных. Применяйте те же условия, что и для io-потоков.
- Для `BatchMessageConsumer` изучите метод `poll()` и экспериментируйте с параметрами:
  - `fetch.min.bytes`: минимальный объём данных (в байтах) для одного запроса к брокеру.
  - `fetch.max.wait.ms`: максимальное время ожидания данных от брокера.
- Для ручного управления оффсетами используйте:
  - **Go**: `consumer.Commit()`
- Консьюмеры должны работать параллельно и считывать одни и те же сообщения. Для этого задайте уникальный `group_id` для каждого типа консьюмера.
- При ошибках консьюмеры должны логировать их и продолжать работу.
- Запустите каждый консьюмер в **двух экземплярах** (используйте параметр `replicas` в `docker-compose`).

###  Шаг 3. Сериализация и десериализация
- Выберите формат данных для сообщений.
- Создайте класс сообщения, сериализуйте его перед отправкой в Kafka и выведите на консоль.
- Реализуйте десериализацию в консьюмерах и выведите полученные сообщения на консоль.
- При проблемах с сериализацией/десериализацией выводите сообщения об ошибках на консоль.

###  Шаг 4. Гарантии доставки
- Настройте подтверждение доставки для продюсера с гарантией **At Least Once**.
- Используйте параметр `acks` для настройки подтверждений.
- Настройте параметр `retries` в продюсере.

## Как должен выглядеть результат
Выполненное задание должно включать:
1. **Рабочий код** с чёткой структурой.
2. **docker-compose** для старта кластера.
3. **Пояснения**:
   - В комментариях к коду укажите, за что отвечает каждый параметр.
   - В файле `Readme.md`:
     - Опишите классы.
     - Укажите инструкцию по запуску и проверке проекта.
     - Поясните принцип работы приложения или его отдельных классов.
     - Опишите шаги для проверки соответствия задания.
4. Файл `topic.txt`:
   - Команда создания топика.
   - Подробная информация о топике (используйте команду `kafka-topics.sh --describe --topic my-topic --bootstrap-server localhost:9092`).

## Как отправить проект на проверку
1. Выполните проект и залейте решение в папку репозитория на GitHub.
2. Приложите одну ссылку:
   - Сделайте репозиторий доступным для ревью и пришлите ссылку.
   - Или соберите проект в zip-архив, выложите на Яндекс Диск и пришлите ссылку на скачивание.
3. Ревьюер проверяет работу за ~48 часов (иногда дольше) и может отправить комментарии для доработки.
4. Учтите комментарии, доработайте проект и отправьте на повторную проверку (до трёх итераций).
5. Проект завершён, когда ревьюер засчитает все доработки.